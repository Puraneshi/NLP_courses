{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "# remove punctuation, string.punctuation\n",
    "# tokenize, nltk.t\n",
    "# remove stopwords, nltk.corpus.stopwords.words('language')\n",
    "# lemmatize, nltk.WordNetLemmatizer()\n",
    "# vectorizing(bow, count vectorizing, n-gram vectorizing, tf-idf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "['ARLSTem',\n 'ARLSTem2',\n 'AbstractLazySequence',\n 'AffixTagger',\n 'AlignedSent',\n 'Alignment',\n 'AnnotationTask',\n 'ApplicationExpression',\n 'Assignment',\n 'BigramAssocMeasures',\n 'BigramCollocationFinder',\n 'BigramTagger',\n 'BinaryMaxentFeatureEncoding',\n 'BlanklineTokenizer',\n 'BllipParser',\n 'BottomUpChartParser',\n 'BottomUpLeftCornerChartParser',\n 'BottomUpProbabilisticChartParser',\n 'Boxer',\n 'BrillTagger',\n 'BrillTaggerTrainer',\n 'CFG',\n 'CRFTagger',\n 'CfgReadingCommand',\n 'ChartParser',\n 'ChunkParserI',\n 'ChunkScore',\n 'Cistem',\n 'ClassifierBasedPOSTagger',\n 'ClassifierBasedTagger',\n 'ClassifierI',\n 'ConcordanceIndex',\n 'ConditionalExponentialClassifier',\n 'ConditionalFreqDist',\n 'ConditionalProbDist',\n 'ConditionalProbDistI',\n 'ConfusionMatrix',\n 'ContextIndex',\n 'ContextTagger',\n 'ContingencyMeasures',\n 'CoreNLPDependencyParser',\n 'CoreNLPParser',\n 'Counter',\n 'CrossValidationProbDist',\n 'DRS',\n 'DecisionTreeClassifier',\n 'DefaultTagger',\n 'DependencyEvaluator',\n 'DependencyGrammar',\n 'DependencyGraph',\n 'DependencyProduction',\n 'DictionaryConditionalProbDist',\n 'DictionaryProbDist',\n 'DiscourseTester',\n 'DrtExpression',\n 'DrtGlueReadingCommand',\n 'ELEProbDist',\n 'EarleyChartParser',\n 'Expression',\n 'FStructure',\n 'FeatDict',\n 'FeatList',\n 'FeatStruct',\n 'FeatStructReader',\n 'Feature',\n 'FeatureBottomUpChartParser',\n 'FeatureBottomUpLeftCornerChartParser',\n 'FeatureChartParser',\n 'FeatureEarleyChartParser',\n 'FeatureIncrementalBottomUpChartParser',\n 'FeatureIncrementalBottomUpLeftCornerChartParser',\n 'FeatureIncrementalChartParser',\n 'FeatureIncrementalTopDownChartParser',\n 'FeatureTopDownChartParser',\n 'FreqDist',\n 'HTTPPasswordMgrWithDefaultRealm',\n 'HeldoutProbDist',\n 'HiddenMarkovModelTagger',\n 'HiddenMarkovModelTrainer',\n 'HunposTagger',\n 'IBMModel',\n 'IBMModel1',\n 'IBMModel2',\n 'IBMModel3',\n 'IBMModel4',\n 'IBMModel5',\n 'ISRIStemmer',\n 'ImmutableMultiParentedTree',\n 'ImmutableParentedTree',\n 'ImmutableProbabilisticMixIn',\n 'ImmutableProbabilisticTree',\n 'ImmutableTree',\n 'IncrementalBottomUpChartParser',\n 'IncrementalBottomUpLeftCornerChartParser',\n 'IncrementalChartParser',\n 'IncrementalLeftCornerChartParser',\n 'IncrementalTopDownChartParser',\n 'Index',\n 'InsideChartParser',\n 'JSONTaggedDecoder',\n 'JSONTaggedEncoder',\n 'KneserNeyProbDist',\n 'LancasterStemmer',\n 'LaplaceProbDist',\n 'LazyConcatenation',\n 'LazyEnumerate',\n 'LazyIteratorList',\n 'LazyMap',\n 'LazySubsequence',\n 'LazyZip',\n 'LeftCornerChartParser',\n 'LegalitySyllableTokenizer',\n 'LidstoneProbDist',\n 'LineTokenizer',\n 'LogicalExpressionException',\n 'LongestChartParser',\n 'MLEProbDist',\n 'MWETokenizer',\n 'Mace',\n 'MaceCommand',\n 'MaltParser',\n 'MaxentClassifier',\n 'Model',\n 'MultiClassifierI',\n 'MultiParentedTree',\n 'MutableProbDist',\n 'NLTKWordTokenizer',\n 'NaiveBayesClassifier',\n 'NaiveBayesDependencyScorer',\n 'NgramAssocMeasures',\n 'NgramTagger',\n 'NonprojectiveDependencyParser',\n 'Nonterminal',\n 'OrderedDict',\n 'PCFG',\n 'Paice',\n 'ParallelProverBuilder',\n 'ParallelProverBuilderCommand',\n 'ParentedTree',\n 'ParserI',\n 'PerceptronTagger',\n 'PhraseTable',\n 'PorterStemmer',\n 'PositiveNaiveBayesClassifier',\n 'ProbDistI',\n 'ProbabilisticDependencyGrammar',\n 'ProbabilisticMixIn',\n 'ProbabilisticNonprojectiveParser',\n 'ProbabilisticProduction',\n 'ProbabilisticProjectiveDependencyParser',\n 'ProbabilisticTree',\n 'Production',\n 'ProjectiveDependencyParser',\n 'Prover9',\n 'Prover9Command',\n 'ProxyBasicAuthHandler',\n 'ProxyDigestAuthHandler',\n 'ProxyHandler',\n 'PunktSentenceTokenizer',\n 'QuadgramAssocMeasures',\n 'QuadgramCollocationFinder',\n 'RSLPStemmer',\n 'RTEFeatureExtractor',\n 'RUS_PICKLE',\n 'RandomChartParser',\n 'RangeFeature',\n 'ReadingCommand',\n 'RecursiveDescentParser',\n 'RegexpChunkParser',\n 'RegexpParser',\n 'RegexpStemmer',\n 'RegexpTagger',\n 'RegexpTokenizer',\n 'ReppTokenizer',\n 'ResolutionProver',\n 'ResolutionProverCommand',\n 'SExprTokenizer',\n 'SLASH',\n 'Senna',\n 'SennaChunkTagger',\n 'SennaNERTagger',\n 'SennaTagger',\n 'SequentialBackoffTagger',\n 'ShiftReduceParser',\n 'SimpleGoodTuringProbDist',\n 'SklearnClassifier',\n 'SlashFeature',\n 'SnowballStemmer',\n 'SpaceTokenizer',\n 'StackDecoder',\n 'StanfordNERTagger',\n 'StanfordPOSTagger',\n 'StanfordSegmenter',\n 'StanfordTagger',\n 'StemmerI',\n 'SteppingChartParser',\n 'SteppingRecursiveDescentParser',\n 'SteppingShiftReduceParser',\n 'SyllableTokenizer',\n 'TYPE',\n 'TabTokenizer',\n 'TableauProver',\n 'TableauProverCommand',\n 'TaggerI',\n 'TestGrammar',\n 'Text',\n 'TextCat',\n 'TextCollection',\n 'TextTilingTokenizer',\n 'TnT',\n 'TokenSearcher',\n 'ToktokTokenizer',\n 'TopDownChartParser',\n 'TransitionParser',\n 'Tree',\n 'TreePrettyPrinter',\n 'TreebankWordDetokenizer',\n 'TreebankWordTokenizer',\n 'Trie',\n 'TrigramAssocMeasures',\n 'TrigramCollocationFinder',\n 'TrigramTagger',\n 'TweetTokenizer',\n 'TypedMaxentFeatureEncoding',\n 'Undefined',\n 'UniformProbDist',\n 'UnigramTagger',\n 'UnsortedChartParser',\n 'Valuation',\n 'Variable',\n 'ViterbiParser',\n 'WekaClassifier',\n 'WhitespaceTokenizer',\n 'WittenBellProbDist',\n 'WordNetLemmatizer',\n 'WordPunctTokenizer',\n '__author__',\n '__author_email__',\n '__builtins__',\n '__cached__',\n '__classifiers__',\n '__copyright__',\n '__doc__',\n '__file__',\n '__keywords__',\n '__license__',\n '__loader__',\n '__longdescr__',\n '__maintainer__',\n '__maintainer_email__',\n '__name__',\n '__package__',\n '__path__',\n '__spec__',\n '__url__',\n '__version__',\n 'accuracy',\n 'acyclic_branches_depth_first',\n 'acyclic_breadth_first',\n 'acyclic_depth_first',\n 'acyclic_dic2tree',\n 'add_logs',\n 'agreement',\n 'align',\n 'alignment_error_rate',\n 'aline',\n 'api',\n 'app',\n 'apply_features',\n 'approxrand',\n 'arity',\n 'arlstem',\n 'arlstem2',\n 'association',\n 'bigrams',\n 'binary_distance',\n 'binary_search_file',\n 'binding_ops',\n 'bisect',\n 'blankline_tokenize',\n 'bleu',\n 'bleu_score',\n 'bllip',\n 'boolean_ops',\n 'boxer',\n 'bracket_parse',\n 'breadth_first',\n 'brill',\n 'brill_trainer',\n 'build_opener',\n 'call_megam',\n 'casual',\n 'casual_tokenize',\n 'ccg',\n 'chain',\n 'chart',\n 'chat',\n 'chomsky_normal_form',\n 'choose',\n 'chrf',\n 'chrf_score',\n 'chunk',\n 'cistem',\n 'classify',\n 'clause',\n 'clean_html',\n 'clean_url',\n 'collapse_unary',\n 'collections',\n 'collocations',\n 'combinations',\n 'compat',\n 'config_java',\n 'config_megam',\n 'config_weka',\n 'conflicts',\n 'confusionmatrix',\n 'conllstr2tree',\n 'conlltags2tree',\n 'corenlp',\n 'corpus',\n 'crf',\n 'custom_distance',\n 'data',\n 'decisiontree',\n 'decorator',\n 'decorators',\n 'defaultdict',\n 'demo',\n 'dependencygraph',\n 'deprecated',\n 'deque',\n 'destructive',\n 'discourse',\n 'distance',\n 'download',\n 'download_gui',\n 'download_shell',\n 'downloader',\n 'draw',\n 'drt',\n 'earleychart',\n 'edge_closure',\n 'edges2dot',\n 'edit_distance',\n 'edit_distance_align',\n 'elementtree_indent',\n 'entropy',\n 'equality_preds',\n 'evaluate',\n 'evaluate_sents',\n 'everygrams',\n 'extract',\n 'extract_rels',\n 'extract_test_sentences',\n 'f_measure',\n 'featstruct',\n 'featurechart',\n 'filestring',\n 'find',\n 'flatten',\n 'fractional_presence',\n 'gale_church',\n 'gdfa',\n 'getproxies',\n 'ghd',\n 'gleu',\n 'gleu_score',\n 'glue',\n 'grammar',\n 'grow_diag_final_and',\n 'guess_encoding',\n 'help',\n 'hmm',\n 'hunpos',\n 'ibm1',\n 'ibm2',\n 'ibm3',\n 'ibm4',\n 'ibm5',\n 'ibm_model',\n 'ieerstr2tree',\n 'in_idle',\n 'induce_pcfg',\n 'inference',\n 'infile',\n 'inspect',\n 'install_opener',\n 'internals',\n 'interpret_sents',\n 'interval_distance',\n 'invert_dict',\n 'invert_graph',\n 'is_rel',\n 'islice',\n 'isri',\n 'jaccard_distance',\n 'json_tags',\n 'jsontags',\n 'lancaster',\n 'lazyimport',\n 'legality_principle',\n 'lfg',\n 'line_tokenize',\n 'linearlogic',\n 'lm',\n 'load',\n 'load_parser',\n 'locale',\n 'log_likelihood',\n 'logic',\n 'mace',\n 'malt',\n 'map_tag',\n 'mapping',\n 'masi_distance',\n 'maxent',\n 'megam',\n 'memoize',\n 'meteor',\n 'meteor_score',\n 'metrics',\n 'misc',\n 'mwe',\n 'naivebayes',\n 'ne_chunk',\n 'ne_chunk_sents',\n 'ngrams',\n 'nist',\n 'nist_score',\n 'nonprojectivedependencyparser',\n 'nonterminals',\n 'os',\n 'pad_sequence',\n 'paice',\n 'pairwise',\n 'parallelize_preprocess',\n 'parse',\n 'parse_sents',\n 'pchart',\n 'perceptron',\n 'phrase_based',\n 'pk',\n 'porter',\n 'pos_tag',\n 'pos_tag_sents',\n 'positivenaivebayes',\n 'pprint',\n 'pr',\n 'precision',\n 'presence',\n 'print_string',\n 'probability',\n 'projectivedependencyparser',\n 'prover9',\n 'punkt',\n 'pydoc',\n 'raise_unorderable_types',\n 'ranks_from_scores',\n 'ranks_from_sequence',\n 're',\n 're_show',\n 'read_grammar',\n 'read_logic',\n 'read_valuation',\n 'recall',\n 'recursivedescent',\n 'regexp',\n 'regexp_span_tokenize',\n 'regexp_tokenize',\n 'register_tag',\n 'relextract',\n 'repp',\n 'resolution',\n 'ribes',\n 'ribes_score',\n 'root_semrep',\n 'rslp',\n 'rte_classifier',\n 'rte_classify',\n 'rte_features',\n 'rtuple',\n 'scikitlearn',\n 'scores',\n 'segmentation',\n 'sem',\n 'senna',\n 'sent_tokenize',\n 'sequential',\n 'set2rel',\n 'set_proxy',\n 'sexpr',\n 'sexpr_tokenize',\n 'shiftreduce',\n 'simple',\n 'sinica_parse',\n 'skipgrams',\n 'skolemize',\n 'slice_bounds',\n 'snowball',\n 'sonority_sequencing',\n 'spearman',\n 'spearman_correlation',\n 'stack_decoder',\n 'stanford',\n 'stanford_segmenter',\n 'stem',\n 'str2tuple',\n 'string_span_tokenize',\n 'subprocess',\n 'subsumes',\n 'sum_logs',\n 'tableau',\n 'tadm',\n 'tag',\n 'tagset_mapping',\n 'tagstr2tree',\n 'tbl',\n 'tee',\n 'text',\n 'textcat',\n 'texttiling',\n 'textwrap',\n 'tkinter',\n 'tnt',\n 'tokenize',\n 'tokenwrap',\n 'toktok',\n 'toolbox',\n 'total_ordering',\n 'trace',\n 'transitionparser',\n 'transitive_closure',\n 'translate',\n 'tree',\n 'tree2conllstr',\n 'tree2conlltags',\n 'treebank',\n 'trigrams',\n 'tuple2str',\n 'un_chomsky_normal_form',\n 'unify',\n 'unique_list',\n 'untag',\n 'unweighted_minimum_spanning_dict',\n 'unweighted_minimum_spanning_digraph',\n 'unweighted_minimum_spanning_tree',\n 'usage',\n 'util',\n 'version_file',\n 'viterbi',\n 'warnings',\n 'weka',\n 'windowdiff',\n 'word_tokenize',\n 'wordnet',\n 'wordpunct_tokenize',\n 'wsd']"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nltk)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "['i', 'herself', 'been', 'with', 'here', 'very', 'doesn', 'won']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords.words('english')[:500:25]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "\"ham\\tI've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\\nspam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\\nham\\tNah I don't think he goes to usf, he lives around here though\\nham\\tEven my brother is not like to speak with me. They treat me like aid\""
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawdata = open(\"SMSSpamCollection.tsv\").read()\n",
    "\n",
    "rawdata[:500]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "['ham',\n \"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\",\n 'spam',\n \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n 'ham']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsedData = rawdata.replace('\\t', '\\n').split('\\n')\n",
    "parsedData[:5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "labelList = parsedData[::2]\n",
    "textList = parsedData[1::2]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(['ham', 'spam', 'ham', 'ham', 'ham', 'ham', 'spam', 'spam', 'ham', 'spam'],\n [\"I've been searching for the right words to thank you for this breather. I promise i wont take your help for granted and will fulfil my promise. You have been wonderful and a blessing at all times.\",\n  \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n  \"Nah I don't think he goes to usf, he lives around here though\",\n  'Even my brother is not like to speak with me. They treat me like aids patent.',\n  'I HAVE A DATE ON SUNDAY WITH WILL!!',\n  \"As per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\",\n  'WINNER!! As a valued network customer you have been selected to receivea £900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n  'Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030',\n  \"I'm gonna be home soon and i don't want to talk about this stuff anymore tonight, k? I've cried enough today.\",\n  'SIX chances to win CASH! From 100 to 20,000 pounds txt> CSH11 and send to 87575. Cost 150p/day, 6days, 16+ TsandCs apply Reply HL 4 info'])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList[:10], textList[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['ham', 'ham', 'ham', 'ham', '']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelList[-5:]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "  label                                          body_list\n0   ham  I've been searching for the right words to tha...\n1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n2   ham  Nah I don't think he goes to usf, he lives aro...\n3   ham  Even my brother is not like to speak with me. ...\n4   ham                I HAVE A DATE ON SUNDAY WITH WILL!!",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>body_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>I've been searching for the right words to tha...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fullCorpus = pd.DataFrame({\n",
    "    'label': labelList[:-1],\n",
    "    'body_list': textList\n",
    "})\n",
    "fullCorpus.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "     label                                          body_list\n0      ham  I've been searching for the right words to tha...\n1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n2      ham  Nah I don't think he goes to usf, he lives aro...\n3      ham  Even my brother is not like to speak with me. ...\n4      ham                I HAVE A DATE ON SUNDAY WITH WILL!!\n...    ...                                                ...\n5563  spam  This is the 2nd time we have tried 2 contact u...\n5564   ham               Will ü b going to esplanade fr home?\n5565   ham  Pity, * was in mood for that. So...any other s...\n5566   ham  The guy did some bitching but I acted like i'd...\n5567   ham                         Rofl. Its true to its name\n\n[5568 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>body_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>I've been searching for the right words to tha...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5563</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5564</th>\n      <td>ham</td>\n      <td>Will ü b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5565</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5568 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t', names=['label', 'body_list'])\n",
    "dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "       label               body_list\ncount   5568                    5568\nunique     2                    5165\ntop      ham  Sorry, I'll call later\nfreq    4822                      30",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>body_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>5568</td>\n      <td>5568</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>2</td>\n      <td>5165</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ham</td>\n      <td>Sorry, I'll call later</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>4822</td>\n      <td>30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "(0, 0)"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty values in labels and body\n",
    "dataset['label'].isnull().sum(), dataset['body_list'].isnull().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "data": {
      "text/plain": "     label                                          body_list\n1     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n5      ham  As per your request 'Melle Melle (Oru Minnamin...\n6     spam  WINNER!! As a valued network customer you have...\n7     spam  Had your mobile 11 months or more? U R entitle...\n9     spam  SIX chances to win CASH! From 100 to 20,000 po...\n...    ...                                                ...\n5553   ham  No. I meant the calculation is the same. That ...\n5558   ham  Ok lor... Sony ericsson salesman... I ask shuh...\n5559   ham                                Ard 6 like dat lor.\n5562  spam  REMINDER FROM O2: To get 2.50 pounds free call...\n5563  spam  This is the 2nd time we have tried 2 contact u...\n\n[1462 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>body_list</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ham</td>\n      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>spam</td>\n      <td>WINNER!! As a valued network customer you have...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>spam</td>\n      <td>Had your mobile 11 months or more? U R entitle...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>spam</td>\n      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5553</th>\n      <td>ham</td>\n      <td>No. I meant the calculation is the same. That ...</td>\n    </tr>\n    <tr>\n      <th>5558</th>\n      <td>ham</td>\n      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n    </tr>\n    <tr>\n      <th>5559</th>\n      <td>ham</td>\n      <td>Ard 6 like dat lor.</td>\n    </tr>\n    <tr>\n      <th>5562</th>\n      <td>spam</td>\n      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n    </tr>\n    <tr>\n      <th>5563</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1462 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regex example search\n",
    "dataset[dataset['body_list'].str.contains('[0-9]')]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "re_test = 'This is a made up string to test 2 different regex methods'\n",
    "re_test_messy = 'This     is a made up    string to test 2    different regex methods'\n",
    "re_test_messy1 = 'This>>>>is_a_made*****up!!!string<<<to>>>>test_2_different{}regex///methods'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "data": {
      "text/plain": "['This',\n '>',\n '>',\n '>',\n '>',\n 'is_a_made',\n '*',\n '*',\n '*',\n '*',\n '*',\n 'up',\n '!',\n '!',\n '!',\n 'string',\n '<',\n '<',\n '<',\n 'to',\n '>',\n '>',\n '>',\n '>',\n 'test_2_different',\n '{',\n '}',\n 'regex///methods']"
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.tokenize.word_tokenize(re_test_messy1,)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}