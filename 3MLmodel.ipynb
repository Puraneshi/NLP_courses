{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## First Step:\n",
    "### Preparing our data as previously seen\n",
    "We have:\n",
    ". character count\n",
    ". punctuation percentage(transformed into a balanced distribution)\n",
    ". coleman-liau index\n",
    ". tf-idf values for each token."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import string\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "body_len = data['body_text'].str.replace(' ', '').str.len()\n",
    "data['body_len'] = body_len\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return count / (len(text) - text.count(' ')) * 100\n",
    "data['punct%'] = data['body_text'].apply(count_punct)\n",
    "\n",
    "def coleman_liau_index(text):\n",
    "    n_sent = len(sent_tokenize(text))\n",
    "    n_words = len(word_tokenize(text))\n",
    "    n_letters = len(text) - text.count(' ')\n",
    "    return 5.88 * (n_letters/n_words) - 29.6 * (n_sent/n_words) - 15.8\n",
    "data['cl_index'] = data['body_text'].apply(coleman_liau_index)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     label                                          body_text  body_len  \\\n0     spam  Free entry in 2 a wkly comp to win FA Cup fina...       128   \n1      ham  Nah I don't think he goes to usf, he lives aro...        49   \n2      ham  Even my brother is not like to speak with me. ...        62   \n3      ham                I HAVE A DATE ON SUNDAY WITH WILL!!        28   \n4      ham  As per your request 'Melle Melle (Oru Minnamin...       135   \n...    ...                                                ...       ...   \n5562  spam  This is the 2nd time we have tried 2 contact u...       131   \n5563   ham               Will ü b going to esplanade fr home?        29   \n5564   ham  Pity, * was in mood for that. So...any other s...        48   \n5565   ham  The guy did some bitching but I acted like i'd...       100   \n5566   ham                         Rofl. Its true to its name        21   \n\n         punct%  cl_index  \n0      4.687500  2.941622  \n1      4.081633  1.434667  \n2      3.225806  1.164444  \n3      7.142857 -5.256000  \n4      4.444444  7.896774  \n...         ...       ...  \n5562   6.106870  2.825143  \n5563   3.448276 -0.142222  \n5564  14.583333 -0.930667  \n5565   1.000000  4.881481  \n5566   4.761905 -6.617143  \n\n[5567 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>body_text</th>\n      <th>body_len</th>\n      <th>punct%</th>\n      <th>cl_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n      <td>128</td>\n      <td>4.687500</td>\n      <td>2.941622</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n      <td>49</td>\n      <td>4.081633</td>\n      <td>1.434667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ham</td>\n      <td>Even my brother is not like to speak with me. ...</td>\n      <td>62</td>\n      <td>3.225806</td>\n      <td>1.164444</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n      <td>28</td>\n      <td>7.142857</td>\n      <td>-5.256000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n      <td>135</td>\n      <td>4.444444</td>\n      <td>7.896774</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5562</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n      <td>131</td>\n      <td>6.106870</td>\n      <td>2.825143</td>\n    </tr>\n    <tr>\n      <th>5563</th>\n      <td>ham</td>\n      <td>Will ü b going to esplanade fr home?</td>\n      <td>29</td>\n      <td>3.448276</td>\n      <td>-0.142222</td>\n    </tr>\n    <tr>\n      <th>5564</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n      <td>48</td>\n      <td>14.583333</td>\n      <td>-0.930667</td>\n    </tr>\n    <tr>\n      <th>5565</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n      <td>100</td>\n      <td>1.000000</td>\n      <td>4.881481</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n      <td>21</td>\n      <td>4.761905</td>\n      <td>-6.617143</td>\n    </tr>\n  </tbody>\n</table>\n<p>5567 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "wl = nltk.WordNetLemmatizer()\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wl.lemmatize(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "X = pd.DataFrame(X_tfidf.toarray())\n",
    "X.columns = tfidf_vect.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "             0  008704050406  0089my  0121  01223585236  01223585334  \\\n0     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n1     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n2     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n3     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n4     0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n...   ...  ...           ...     ...   ...          ...          ...   \n5562  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n5563  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n5564  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n5565  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n5566  0.0  0.0           0.0     0.0   0.0          0.0          0.0   \n\n      0125698789   02  020603  ...  zoom  zouk  zyada    é        ü  üll  〨ud  \\\n0            0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n1            0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n2            0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n3            0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n4            0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n...          ...  ...     ...  ...   ...   ...    ...  ...      ...  ...  ...   \n5562         0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n5563         0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.32906  0.0  0.0   \n5564         0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n5565         0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n5566         0.0  0.0     0.0  ...   0.0   0.0    0.0  0.0  0.00000  0.0  0.0   \n\n      body_len    punct%  cl_index  \n0          128  1.362035  2.941622  \n1           49  1.324850  1.434667  \n2           62  1.263944  1.164444  \n3           28  1.481748 -5.256000  \n4          135  1.347608  7.896774  \n...        ...       ...       ...  \n5562       131  1.436031  2.825143  \n5563        29  1.280915 -0.142222  \n5564        48  1.709115 -0.930667  \n5565       100  1.000000  4.881481  \n5566        21  1.366332 -6.617143  \n\n[5567 rows x 8914 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>008704050406</th>\n      <th>0089my</th>\n      <th>0121</th>\n      <th>01223585236</th>\n      <th>01223585334</th>\n      <th>0125698789</th>\n      <th>02</th>\n      <th>020603</th>\n      <th>...</th>\n      <th>zoom</th>\n      <th>zouk</th>\n      <th>zyada</th>\n      <th>é</th>\n      <th>ü</th>\n      <th>üll</th>\n      <th>〨ud</th>\n      <th>body_len</th>\n      <th>punct%</th>\n      <th>cl_index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>128</td>\n      <td>1.362035</td>\n      <td>2.941622</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49</td>\n      <td>1.324850</td>\n      <td>1.434667</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>62</td>\n      <td>1.263944</td>\n      <td>1.164444</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>28</td>\n      <td>1.481748</td>\n      <td>-5.256000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>135</td>\n      <td>1.347608</td>\n      <td>7.896774</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5562</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>131</td>\n      <td>1.436031</td>\n      <td>2.825143</td>\n    </tr>\n    <tr>\n      <th>5563</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.32906</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>29</td>\n      <td>1.280915</td>\n      <td>-0.142222</td>\n    </tr>\n    <tr>\n      <th>5564</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>48</td>\n      <td>1.709115</td>\n      <td>-0.930667</td>\n    </tr>\n    <tr>\n      <th>5565</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>100</td>\n      <td>1.000000</td>\n      <td>4.881481</td>\n    </tr>\n    <tr>\n      <th>5566</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.00000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>21</td>\n      <td>1.366332</td>\n      <td>-6.617143</td>\n    </tr>\n  </tbody>\n</table>\n<p>5567 rows × 8914 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['body_len'] = data['body_len']\n",
    "X['punct%'] = data['punct%']**(1/5) # our transformation seen on feature_engineering\n",
    "X['cl_index'] = data['cl_index']\n",
    "y = data['label']\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Second Step:\n",
    "### Training and cross-validating\n",
    "\n",
    "Models to use:\n",
    ". Random forest\n",
    ". XGBoost\n",
    ". Neural Networks(?)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "<Signature (n_estimators=100, *, criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None)>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import inspect\n",
    "\n",
    "inspect.signature(RandomForestClassifier)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.97755835, 0.97755835, 0.97394429, 0.96675651, 0.97214735])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "k_fold = KFold(n_splits=5)\n",
    "cross_val_score(rf, X, y, cv=k_fold, scoring='accuracy', n_jobs=-1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Third Step\n",
    "### Exploring the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "       Feature  Importance\n8911  body_len    0.050803\n8913  cl_index    0.032452\n1899      call    0.032016\n2154     claim    0.020344\n8100       txt    0.020127\n...        ...         ...\n5791    outage    0.000000\n5793  outdoors    0.000000\n5794    outfit    0.000000\n5795    outfor    0.000000\n4457      jsut    0.000000\n\n[8914 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8911</th>\n      <td>body_len</td>\n      <td>0.050803</td>\n    </tr>\n    <tr>\n      <th>8913</th>\n      <td>cl_index</td>\n      <td>0.032452</td>\n    </tr>\n    <tr>\n      <th>1899</th>\n      <td>call</td>\n      <td>0.032016</td>\n    </tr>\n    <tr>\n      <th>2154</th>\n      <td>claim</td>\n      <td>0.020344</td>\n    </tr>\n    <tr>\n      <th>8100</th>\n      <td>txt</td>\n      <td>0.020127</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5791</th>\n      <td>outage</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5793</th>\n      <td>outdoors</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5794</th>\n      <td>outfit</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>5795</th>\n      <td>outfor</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4457</th>\n      <td>jsut</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8914 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X, y)\n",
    "feature_importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "pd.DataFrame(\n",
    "    {\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "    }\n",
    ").sort_values(by='Importance', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=50,\n",
    "                            max_depth=20,\n",
    "                            n_jobs=-1)\n",
    "rf_model = rf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "[(0.05807321618366297, 'body_len'),\n (0.049522480809207584, 'cl_index'),\n (0.04357468031941846, 'txt'),\n (0.02364131295826045, 'text'),\n (0.02215134385074408, 'call'),\n (0.022131508081918813, 'free'),\n (0.021330942481623004, 'prize'),\n (0.020887526581213893, 'mobile'),\n (0.020541441848161524, 'win'),\n (0.020222884267934126, 'claim')]"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_, X_train.columns), reverse=True)[:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "precision, recall, fscore, support = score(y_test,\n",
    "                                           y_pred,\n",
    "                                           pos_label='spam',\n",
    "                                           average='binary')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "(1.0, 0.6089743589743589)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision, recall"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Some grid searching"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "405 fits failed out of a total of 810.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "217 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "188 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/leo_rsnd/miniconda3/envs/nlp/lib/python3.10/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.97395155 0.97521006 0.97520958\n",
      " 0.97431191 0.97502972 0.97521006 0.97449177 0.97485067 0.97574834\n",
      " 0.96964034 0.96964018 0.96928111 0.96910174 0.96784484 0.96874219\n",
      " 0.97000037 0.97107757 0.96982019 0.96030042 0.95976133 0.96047963\n",
      " 0.96155699 0.96137729 0.96065964 0.96119824 0.96011991 0.96029977\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.89814837 0.89760993 0.89689212\n",
      " 0.89940672 0.8995869  0.89653273 0.89419703 0.89599301 0.89617222\n",
      " 0.89294094 0.89221942 0.89473531 0.89168147 0.89563362 0.89294013\n",
      " 0.89491468 0.89563491 0.89312031 0.89204231 0.8924017  0.89024568\n",
      " 0.89617367 0.89222168 0.89204069 0.89222055 0.89204182 0.892222\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.94251776 0.94647039 0.94575113\n",
      " 0.94377352 0.94647023 0.94395483 0.94233645 0.94431357 0.94557143\n",
      " 0.93892612 0.94054241 0.94090196 0.93856512 0.94215837 0.94161977\n",
      " 0.93964426 0.9394644  0.94072178 0.93353626 0.93587148 0.93551161\n",
      " 0.93551144 0.93461475 0.93605037 0.93353513 0.93641072 0.93658993]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best score: 0.9757483373417793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "# Create a RandomForestClassifier instance\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Create GridSearchCV instance\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "\n",
    "# Fit the grid search to your data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Last step:\n",
    "### Check out \"holdout learning/training\"\n",
    "It's the concept that real word data will have tokens not available in our model. So we split the data into train and test BEFORE applying the transformations. Meaning our vocabulary will probably be smaller."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}